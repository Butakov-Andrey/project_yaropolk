from typing import Generator

import openai
from config import settings
from loguru import logger

from .constants import Gpt3_5Constants
from .mongo_crud import ContextManager


class ChatAssistant:
    """
    A class representing a chat assistant that can communicate with users.
    """

    def __init__(
        self, system_prompt: str = Gpt3_5Constants.DEFAULT_SYSTEM_PROMPT
    ) -> None:
        """
        Initializes a new instance of the ChatAssistant class.

        Parameters:
        -----------
        system_prompt : str, optional.
            The prompt to use for the system's messages.
            If not provided, the default prompt will be used.
        """
        self.system_prompt = system_prompt
        self.openai_api_key = settings.OPENAI_API_KEY
        self.openai_organization = settings.ORGANIZATION

    def make_request_to_gpt_api(self, user_prompt: str) -> Generator[str, None, None]:
        """
        Sends a request to the OpenAI API to generate a streaming response.

        Parameters:
        -----------
        user_prompt : str.
            The message input by the user.

        Yields:
        -------
        str.
            A string containing the response messages generated by the API.
        """
        context = ContextManager().get_context()
        messages = [
            {
                "role": Gpt3_5Constants.SYSTEM_ROLE,
                "content": self.system_prompt + context,
            },
            {
                "role": Gpt3_5Constants.USER_ROLE,
                "content": user_prompt,
            },
        ]
        ContextManager().add_message_to_context(
            role=Gpt3_5Constants.USER_ROLE,
            text=user_prompt,
        )
        try:
            openai.organization = self.openai_organization
            openai.api_key = self.openai_api_key
            stream = openai.ChatCompletion.create(
                model=Gpt3_5Constants.MODEL,
                messages=messages,
                temperature=Gpt3_5Constants.TEMPERATURE,
                max_tokens=Gpt3_5Constants.MAX_TOKENS,
                stream=True,
            )
            total_stream_tokens = 0
            full_answer = []
            for chunk in stream:
                total_stream_tokens += 1
                try:
                    # only delte with content, ignore delta with role
                    chunk_message = chunk["choices"][0]["delta"]["content"]
                    full_answer.append(chunk_message)
                    yield from chunk_message
                except KeyError:
                    # if delta is empty - this is the end of the stream
                    if chunk["choices"][0]["delta"] == {}:
                        full_answer_str = "".join(full_answer)
                        ContextManager().add_message_to_context(
                            role=Gpt3_5Constants.ASSISTANT_ROLE,
                            text=full_answer_str,
                        )
                except Exception as e:
                    logger.error(e)
            logger.info(f"Total stream tokens: {total_stream_tokens}")
        except Exception as e:
            logger.error(e)
            stream = f"Hello, dude. Error: `{e}`"
            for chunk in stream:
                yield from chunk


chat_assistant = ChatAssistant()
